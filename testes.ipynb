{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2f7f08c",
   "metadata": {},
   "source": [
    "## Testes usando o pipeline de classificador\n",
    "- Em conjunto com a API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06f4e227",
   "metadata": {},
   "source": [
    "## 1 - Lendo dados do CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeff47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ceef0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_operacao = pd.read_csv(\"dados_operacao.csv\")\n",
    "df_metanol = pd.read_csv(\"dados_metanol.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b82e7df",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_operacao.columns, df_metanol.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1629ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_operacao = df_operacao[[\"Conteúdo\", \"Link\"]].rename(columns={\"Conteúdo\": \"conteudo\", \"Link\": \"link\"})\n",
    "df_metanol = df_metanol[[\"conteudo\", \"link\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4437e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_operacao.columns, df_metanol.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b32ab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_operacao + df_metanol\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7ae709",
   "metadata": {},
   "source": [
    "## 2 - Injetando dados do dataframe na API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec69922",
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"http://localhost:8000/api\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b2c8bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aiohttp\n",
    "from tqdm.asyncio import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d883cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def enviar(LIMITE:int=None):\n",
    "    async with aiohttp.ClientSession() as session:\n",
    "        if LIMITE:\n",
    "            for tweet in tqdm(\n",
    "                df.head(LIMITE).itertuples(),\n",
    "                total=LIMITE,\n",
    "                desc=f\"Enviando tweets do csv com limite {LIMITE}\"\n",
    "            ):\n",
    "                res=await session.post(\n",
    "                    f\"{url}/enqueue\",\n",
    "                    json={\"msg\":tweet.conteudo}\n",
    "                )\n",
    "                res.raise_for_status()\n",
    "        else:\n",
    "            for tweet in tqdm(\n",
    "                df.itertuples(),\n",
    "                total=len(df),\n",
    "                desc=\"Enviando tweets do csv\"\n",
    "            ):\n",
    "                res=await session.post(\n",
    "                    f\"{url}/enqueue\",\n",
    "                    json={\"msg\":tweet.conteudo}\n",
    "                )\n",
    "                res.raise_for_status()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3bb5e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "await enviar(2000)\n",
    "# await enviar(1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29b0022",
   "metadata": {},
   "source": [
    "## 3 - Consumindo dados com o classificador"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "675291fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.processor.classifier import BERTClassifier\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3974de76",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def classificar(WORKERS: int = None, BATCH_SIZE: int = None, LIMITE: int = None):\n",
    "    bert = None\n",
    "    \n",
    "    try:\n",
    "        classifier_kwargs = {}\n",
    "        if WORKERS is not None:\n",
    "            classifier_kwargs['num_workers'] = WORKERS\n",
    "        if BATCH_SIZE is not None:\n",
    "            classifier_kwargs['batch_size'] = BATCH_SIZE\n",
    "        \n",
    "        bert = BERTClassifier(**classifier_kwargs)\n",
    "        await bert.initialize()\n",
    "\n",
    "        async def stop():\n",
    "            if LIMITE:\n",
    "                await asyncio.sleep(LIMITE)\n",
    "            else:\n",
    "                while bert._running:\n",
    "                    await asyncio.sleep(1)\n",
    "            await bert.stop()\n",
    "\n",
    "        await asyncio.gather(\n",
    "            bert.start_consuming(),\n",
    "            stop()\n",
    "        )\n",
    "    except Exception as e:\n",
    "        raise\n",
    "    finally:\n",
    "        if bert:\n",
    "            try:\n",
    "                await bert.stop()\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f62ed416",
   "metadata": {},
   "source": [
    "#### O classificador é configurável"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49608683",
   "metadata": {},
   "outputs": [],
   "source": [
    "await classificar(WORKERS=8, BATCH_SIZE=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4ba02b2",
   "metadata": {},
   "source": [
    "## 4 - Gerador de métricas consumindo do 'dequeue' da API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b900b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "class ClassifierMonitor:\n",
    "    \"\"\"Monitora e visualiza resultados do classificador\"\"\"\n",
    "    \n",
    "    def __init__(self, api_url=\"http://localhost:8000/api\"):\n",
    "        self.api_url = api_url\n",
    "        self.results = []\n",
    "    \n",
    "    async def fetch_message_status(self, session, msg_id):\n",
    "        \"\"\"Busca o status de uma mensagem específica\"\"\"\n",
    "        try:\n",
    "            async with session.get(f\"{self.api_url}/dequeue/{msg_id}\") as response:\n",
    "                if response.status == 200:\n",
    "                    return await response.json()\n",
    "                return None\n",
    "        except Exception as e:\n",
    "            return {\"msg_id\": msg_id, \"error\": str(e)}\n",
    "    \n",
    "    async def fetch_queue_messages(self, redis_client, queue_name, limit=100):\n",
    "        \"\"\"Busca mensagens de uma fila específica\"\"\"\n",
    "        try:\n",
    "            messages = await redis_client.lrange(queue_name, 0, limit - 1)\n",
    "            return [json.loads(msg) for msg in messages]\n",
    "        except Exception as e:\n",
    "            print(f\"Erro ao buscar da fila {queue_name}: {e}\")\n",
    "            return []\n",
    "    \n",
    "    async def collect_results(self, limit=None):\n",
    "        \"\"\"Coleta todos os resultados classificados da fila de saída\"\"\"\n",
    "        from app.redis import get_async_client\n",
    "        \n",
    "        redis_client = await get_async_client()\n",
    "        \n",
    "        try:\n",
    "            classified = await self.fetch_queue_messages(\n",
    "                redis_client, \n",
    "                \"norm_queue_out\", \n",
    "                limit or -1\n",
    "            )\n",
    "            \n",
    "            errors = await self.fetch_queue_messages(\n",
    "                redis_client, \n",
    "                \"norm_queue_errors\", \n",
    "                limit or -1\n",
    "            )\n",
    "            \n",
    "            self.results = classified + errors\n",
    "            \n",
    "        finally:\n",
    "            await redis_client.close()\n",
    "        \n",
    "        return self.results\n",
    "    \n",
    "    def create_summary_df(self):\n",
    "        \"\"\"Cria DataFrame resumido dos resultados coletados\"\"\"\n",
    "        if not self.results:\n",
    "            return pd.DataFrame()\n",
    "        \n",
    "        df = pd.DataFrame(self.results)\n",
    "        \n",
    "        if 'classification' in df.columns:\n",
    "            df['label'] = df['classification'].apply(\n",
    "                lambda x: x.get('label', 'N/A') if isinstance(x, dict) else 'N/A'\n",
    "            )\n",
    "            df['score'] = df['classification'].apply(\n",
    "                lambda x: x.get('score', 0.0) if isinstance(x, dict) else 0.0\n",
    "            )\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    def generate_statistics(self, df):\n",
    "        \"\"\"Gera estatísticas resumidas\"\"\"\n",
    "        if df.empty:\n",
    "            return {}\n",
    "        \n",
    "        stats = {\n",
    "            \"total_messages\": len(df),\n",
    "            \"classified\": len(df[df['status'] == 'classified']),\n",
    "            \"errors\": len(df[df['status'] == 'error']),\n",
    "            \"classification_rate\": 0.0\n",
    "        }\n",
    "        \n",
    "        if stats['total_messages'] > 0:\n",
    "            stats['classification_rate'] = (\n",
    "                stats['classified'] / stats['total_messages'] * 100\n",
    "            )\n",
    "        \n",
    "        if 'label' in df.columns:\n",
    "            stats['label_distribution'] = df['label'].value_counts().to_dict()\n",
    "        \n",
    "        if 'score' in df.columns:\n",
    "            stats['avg_confidence'] = df[df['status'] == 'classified']['score'].mean()\n",
    "            stats['min_confidence'] = df[df['status'] == 'classified']['score'].min()\n",
    "            stats['max_confidence'] = df[df['status'] == 'classified']['score'].max()\n",
    "        \n",
    "        if 'error_type' in df.columns:\n",
    "            error_df = df[df['status'] == 'error']\n",
    "            if not error_df.empty:\n",
    "                stats['error_types'] = error_df['error_type'].value_counts().to_dict()\n",
    "        \n",
    "        return stats\n",
    "    \n",
    "    def display_summary(self, stats):\n",
    "        \"\"\"Exibe resumo formatado\"\"\"\n",
    "        print(\"=\" * 60)\n",
    "        print(\"RESUMO DOS RESULTADOS DO CLASSIFICADOR\")\n",
    "        print(\"=\" * 60)\n",
    "        print(f\"\\nTotal de Mensagens: {stats.get('total_messages', 0)}\")\n",
    "        print(f\"Classificadas com Sucesso: {stats.get('classified', 0)}\")\n",
    "        print(f\"Erros: {stats.get('errors', 0)}\")\n",
    "        print(f\"Taxa de Classificação: {stats.get('classification_rate', 0):.2f}%\")\n",
    "        \n",
    "        if 'avg_confidence' in stats:\n",
    "            print(f\"\\nScores de Confiança:\")\n",
    "            print(f\"  Média: {stats['avg_confidence']:.4f}\")\n",
    "            print(f\"  Mínimo: {stats['min_confidence']:.4f}\")\n",
    "            print(f\"  Máximo: {stats['max_confidence']:.4f}\")\n",
    "        \n",
    "        if 'label_distribution' in stats:\n",
    "            print(f\"\\nDistribuição de Labels:\")\n",
    "            for label, count in stats['label_distribution'].items():\n",
    "                percentage = (count / stats['total_messages']) * 100\n",
    "                print(f\"  {label}: {count} ({percentage:.2f}%)\")\n",
    "        \n",
    "        if 'error_types' in stats:\n",
    "            print(f\"\\nTipos de Erro:\")\n",
    "            for error_type, count in stats['error_types'].items():\n",
    "                print(f\"  {error_type}: {count}\")\n",
    "        \n",
    "        print(\"=\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0748c6d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def analyze_results(limit=None):\n",
    "    \"\"\"Analisa resultados do classificador e exibe resumo\"\"\"\n",
    "    monitor = ClassifierMonitor()\n",
    "    \n",
    "    print(\"Coletando resultados das filas...\")\n",
    "    results = await monitor.collect_results(limit=limit)\n",
    "    \n",
    "    if not results:\n",
    "        print(\"Nenhum resultado encontrado nas filas.\")\n",
    "        return None\n",
    "    \n",
    "    df = monitor.create_summary_df()\n",
    "    \n",
    "    stats = monitor.generate_statistics(df)\n",
    "    \n",
    "    monitor.display_summary(stats)\n",
    "    \n",
    "    return df, stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0841839",
   "metadata": {},
   "outputs": [],
   "source": [
    "df, stats = await analyze_results(limit=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2827412a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None and not df.empty:\n",
    "    print(\"\\nResultados de Amostra:\")\n",
    "    display(df.head(10))\n",
    "    \n",
    "    try:\n",
    "        import matplotlib.pyplot as plt\n",
    "        \n",
    "        if 'label' in df.columns:\n",
    "            df['label_pt'] = df['label'].map({\n",
    "                'true': 'Verdadeiro',\n",
    "                'false': 'Falso',\n",
    "                True: 'Verdadeiro',\n",
    "                False: 'Falso'\n",
    "            }).fillna(df['label'])\n",
    "            \n",
    "            fig, axes = plt.subplots(1, 2, figsize=(15, 6))\n",
    "            \n",
    "            label_counts = df['label_pt'].value_counts()\n",
    "            colors = ['#2ecc71', '#e74c3c', '#3498db', '#f39c12']\n",
    "            explode = [0.05] * len(label_counts)\n",
    "            \n",
    "            axes[0].pie(\n",
    "                label_counts.values, \n",
    "                labels=label_counts.index,\n",
    "                autopct='%1.1f%%',\n",
    "                startangle=90,\n",
    "                colors=colors[:len(label_counts)],\n",
    "                explode=explode,\n",
    "                shadow=True\n",
    "            )\n",
    "            axes[0].set_title('Distribuição de Labels de Classificação', fontsize=14, fontweight='bold')\n",
    "            \n",
    "            if 'score' in df.columns:\n",
    "                classified_scores = df[df['status'] == 'classified']['score']\n",
    "                axes[1].hist(classified_scores, bins=20, color='#3498db', edgecolor='black', alpha=0.7)\n",
    "                axes[1].set_title('Distribuição de Score de Confiança', fontsize=14, fontweight='bold')\n",
    "                axes[1].set_xlabel('Score de Confiança')\n",
    "                axes[1].set_ylabel('Frequência')\n",
    "                axes[1].grid(axis='y', alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    except ImportError:\n",
    "        print(\"\\nInstale matplotlib para visualizações: pip install matplotlib\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "normie",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
